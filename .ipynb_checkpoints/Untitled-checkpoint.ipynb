{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DLWP.dataset.dataloader import DatasetLoader\n",
    "from DLWP.preprocessing.aspectawarepreprocessor import AspectAwarePreprocessor\n",
    "from DLWP.preprocessing.imagetoarraypreprocessor import ImageToArrayPreprocessor\n",
    "from DLWP.preprocessing.bwpreprocessor import BWPreprocessor\n",
    "\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "from DLWP.preprocessing.expand import ExPreprocessor\n",
    "import imutils\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from imutils import paths\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from DLWP.preprocessing import imagetoarraypreprocessor, aspectawarepreprocessor\n",
    "from DLWP.dataset import dataloader\n",
    "from cnn_architectures.fcheadnet import FCHeadNet\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "\n",
    "datapath = \"/home/aniket/Downloads/dataset\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(datapath))\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# loop over the image paths\n",
    "for imagePath in imagePaths:\n",
    "    # extract the class label from the filename\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "\n",
    "    # load the input image (224x224) and preprocess it\n",
    "    image = load_img(imagePath, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "#     image = preprocess_input(image)\n",
    "\n",
    "    # update the data and labels lists, respectively\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "\n",
    "# convert the data and labels to NumPy arrays\n",
    "data = np.array(data, dtype=\"float32\")/255.0\n",
    "labels = np.array(labels)\n",
    "classlabels = labels\n",
    "\n",
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "idx = np.random.permutation(len(labels))\n",
    "data = data[idx]\n",
    "labels = labels[idx]\n",
    "classlabels = classlabels[idx]\n",
    "\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "    test_size=0.15, stratify=labels, random_state=42)\n",
    "\n",
    "print(\"[INFO] Loading Successful...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels[3], classlabels[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[6], classlabels[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(height_shift_range=0.2, width_shift_range=0.2, rotation_range=20,shear_range=0.15, zoom_range=0.15, horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel = MobileNetV2(weights = \"imagenet\", include_top=False, input_tensor = Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headModel = FCHeadNet.build(basemodel,2,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=basemodel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in basemodel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] compiling model\")\n",
    "opt = Adam(lr=Lr)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"[INFO] training model\")\n",
    "H = model.fit_generator(aug.flow(trainX, trainY,batch_size=32), steps_per_epoch=len(trainX)//32, validation_data=(testX, testY), validation_steps=len(testX)//32, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mobilenet_mask_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "figure = plt.figure()\n",
    "plt.plot(np.arange(5),model.history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(np.arange(5),model.history.history[\"val_loss\"], label=\"validation Loss\")\n",
    "plt.plot(np.arange(5),model.history.history[\"acc\"], label=\"Training Accuracy\")\n",
    "plt.plot(np.arange(5),model.history.history[\"val_acc\"], label=\"validation accuracy\")\n",
    "plt.xlabel(\"#Epochs\")\n",
    "plt.ylabel(\"Accuracy/Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss Accuracy Graph\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "witth = \"/home/aniket/IMG_20200512_204128.jpg\"\n",
    "# without = \"/home/aniket/Pictures/Webcam/with.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from DLWP.preprocessing.aspectawarepreprocessor import AspectAwarePreprocessor\n",
    "witth = cv2.imread(witth)\n",
    "# without = cv2.imread(without)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = AspectAwarePreprocessor(224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "witth = ap.preprocess(witth)\n",
    "# without = ap.preprocess(without)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "witth = witth/255.0\n",
    "# without = without/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test = np.array([witth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in a:\n",
    "    if i[0]>i[1]:\n",
    "        print([1,0])\n",
    "        \n",
    "    else:\n",
    "        print([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data[0]*255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model_with = load_model(\"mobilenet_mask_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = model_with.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_label = []\n",
    "for i in r1:\n",
    "    if i[0]>i[1]:\n",
    "        r1_label.append([1,0])\n",
    "        \n",
    "    else:\n",
    "        r1_label.append([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_label = np.array(r1_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(testY, r1_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_label = []\n",
    "for i in r2:\n",
    "    if i[0]>i[1]:\n",
    "        r2_label.append([1,0])\n",
    "        \n",
    "    else:\n",
    "        r2_label.append([0,1])\n",
    "\n",
    "r2_label = np.array(r2_label)\n",
    "print(classification_report(testY, r2_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
